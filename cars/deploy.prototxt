name: "GoogleNet"
input: "data"
input_dim: 10
input_dim: 3
input_dim: 224
input_dim: 224
force_backward: true

# hierarchy 1
# conv -> relu -> pool -> lrn
# ===========================
layers {
  bottom: "data"
  top: "conv1"
  name: "conv1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "conv1"
  top: "conv1"
  name: "relu1"
  type: RELU
}
layers {
  bottom: "conv1"
  top: "pool1"
  name: "pool1"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layers {
  bottom: "pool1"
  top: "norm1"
  name: "norm1"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}

# hierarchy 2
# conv -> relu -> conv -> relu -> lrn -> pool
# ===========================================
layers {
  bottom: "norm1"
  top: "conv2_1x1"
  name: "conv2_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "conv2_1x1"
  top: "conv2_1x1"
  name: "relu_conv2_1x1"
  type: RELU
}
layers {
  bottom: "conv2_1x1"
  top: "conv2_3x3"
  name: "conv2_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "conv2_3x3"
  top: "conv2_3x3"
  name: "relu2_3x3"
  type: RELU
}
layers {
  bottom: "conv2_3x3"
  top: "norm2"
  name: "norm2"
  type: LRN
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layers {
  bottom: "norm2"
  top: "pool2"
  name: "pool2"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}

# ================== hierarchy 3(a) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "pool2"
  top: "inception_3a_1x1"
  name: "inception_3a_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_1x1"
  top: "inception_3a_1x1"
  name: "relu_inception_3a_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "pool2"
  top: "inception_3a_3x3_reduce"
  name: "inception_3a_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_3x3_reduce"
  top: "inception_3a_3x3_reduce"
  name: "reulu_inception_3a_3x3_reduce"
  type: RELU
}

layers {
  bottom: "inception_3a_3x3_reduce"
  top: "inception_3a_3x3"
  name: "inception_3a_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_3x3"
  top: "inception_3a_3x3"
  name: "relu_inception_3a_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "pool2"
  top: "inception_3a_5x5_reduce"
  name: "inception_3a_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_5x5_reduce"
  top: "inception_3a_5x5_reduce"
  name: "relu_inception_3a_5x5_reduce"
  type: RELU
}

layers {
  bottom: "inception_3a_5x5_reduce"
  top: "inception_3a_5x5"
  name: "inception_3a_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_5x5"
  top: "inception_3a_5x5"
  name: "relu_inception_3a_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "pool2"
  top: "inception_3a_pool"
  name: "inception_3a_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_3a_pool"
  top: "inception_3a_pool_proj"
  name: "inception_3a_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3a_pool_proj"
  top: "inception_3a_pool_proj"
  name: "relu_inception_3a_pool_proj"
  type: RELU
}

# concatenate all
# ---------------
layers {
  bottom: "inception_3a_1x1"
  bottom: "inception_3a_3x3"
  bottom: "inception_3a_5x5"
  bottom: "inception_3a_pool_proj"
  top: "inception_3a_output"
  name: "inception_3a_output"
  type: CONCAT
}

# ================== hierarchy 3(b) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_3a_output"
  top: "inception_3b_1x1"
  name: "inception_3b_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_1x1"
  top: "inception_3b_1x1"
  name: "relu_inception_3b_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_3a_output"
  top: "inception_3b_3x3_reduce"
  name: "inception_3b_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_3x3_reduce"
  top: "inception_3b_3x3_reduce"
  name: "relu_inception_3b_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_3b_3x3_reduce"
  top: "inception_3b_3x3"
  name: "inception_3b_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 192
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_3x3"
  top: "inception_3b_3x3"
  name: "relu_inception_3b_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_3a_output"
  top: "inception_3b_5x5_reduce"
  name: "inception_3b_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_5x5_reduce"
  top: "inception_3b_5x5_reduce"
  name: "relu_inception_3b_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_3b_5x5_reduce"
  top: "inception_3b_5x5"
  name: "inception_3b_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 96
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_5x5"
  top: "inception_3b_5x5"
  name: "relu_inception_3b_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_3a_output"
  top: "inception_3b_pool"
  name: "inception_3b_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_3b_pool"
  top: "inception_3b_pool_proj"
  name: "inception_3b_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_3b_pool_proj"
  top: "inception_3b_pool_proj"
  name: "relu_inception_3b_pool_proj"
  type: RELU
}

# concatenate all
# ---------------
layers {
  bottom: "inception_3b_1x1"
  bottom: "inception_3b_3x3"
  bottom: "inception_3b_5x5"
  bottom: "inception_3b_pool_proj"
  top: "inception_3b_output"
  name: "inception_3b_output"
  type: CONCAT
}

layers {
  bottom: "inception_3b_output"
  top: "pool3"
  name: "pool3"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}


# ================== hierarchy 4(a) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "pool3"
  top: "inception_4a_1x1"
  name: "inception_4a_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_1x1"
  top: "inception_4a_1x1"
  name: "relu_inception_4a_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "pool3"
  top: "inception_4a_3x3_reduce"
  name: "inception_4a_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 96
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_3x3_reduce"
  top: "inception_4a_3x3_reduce"
  name: "relu_inception_4a_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_4a_3x3_reduce"
  top: "inception_4a_3x3"
  name: "inception_4a_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 208
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_3x3"
  top: "inception_4a_3x3"
  name: "relu_inception_4a_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "pool3"
  top: "inception_4a_5x5_reduce"
  name: "inception_4a_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 16
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_5x5_reduce"
  top: "inception_4a_5x5_reduce"
  name: "relu_inception_4a_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_4a_5x5_reduce"
  top: "inception_4a_5x5"
  name: "inception_4a_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 48
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_5x5"
  top: "inception_4a_5x5"
  name: "relu_inception_4a_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "pool3"
  top: "inception_4a_pool"
  name: "inception_4a_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_4a_pool"
  top: "inception_4a_pool_proj"
  name: "inception_4a_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4a_pool_proj"
  top: "inception_4a_pool_proj"
  name: "relu_inception_4a_pool_proj"
  type: RELU
}

# concatenate all
# ---------------
layers {
  bottom: "inception_4a_1x1"
  bottom: "inception_4a_3x3"
  bottom: "inception_4a_5x5"
  bottom: "inception_4a_pool_proj"
  top: "inception_4a_output"
  name: "inception_4a_output"
  type: CONCAT
}

# ================== hierarchy 4(b) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_4a_output"
  top: "inception_4b_1x1"
  name: "inception_4b_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_1x1"
  top: "inception_4b_1x1"
  name: "inception_4b_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_4a_output"
  top: "inception_4b_3x3_reduce"
  name: "inception_4b_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_3x3_reduce"
  top: "inception_4b_3x3_reduce"
  name: "inception_4b_relu_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_4b_3x3_reduce"
  top: "inception_4b_3x3"
  name: "inception_4b_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 224
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_3x3"
  top: "inception_4b_3x3"
  name: "inception_4b_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_4a_output"
  top: "inception_4b_5x5_reduce"
  name: "inception_4b_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_5x5_reduce"
  top: "inception_4b_5x5_reduce"
  name: "inception_4b_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_4b_5x5_reduce"
  top: "inception_4b_5x5"
  name: "inception_4b_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_5x5"
  top: "inception_4b_5x5"
  name: "inception_4b_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_4a_output"
  top: "inception_4b_pool"
  name: "inception_4b_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_4b_pool"
  top: "inception_4b_pool_proj"
  name: "inception_4b_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4b_pool_proj"
  top: "inception_4b_pool_proj"
  name: "inception_4b_relu_pool_proj"
  type: RELU
}

# concatenate all
# ---------------
layers {
  bottom: "inception_4b_1x1"
  bottom: "inception_4b_3x3"
  bottom: "inception_4b_5x5"
  bottom: "inception_4b_pool_proj"
  top: "inception_4b_output"
  name: "inception_4b_output"
  type: CONCAT
}

# ================== hierarchy 4(c) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_4b_output"
  top: "inception_4c_1x1"
  name: "inception_4c_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_1x1"
  top: "inception_4c_1x1"
  name: "inception_4c_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_4b_output"
  top: "inception_4c_3x3_reduce"
  name: "inception_4c_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_3x3_reduce"
  top: "inception_4c_3x3_reduce"
  name: "inception_4c_relu_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_4c_3x3_reduce"
  top: "inception_4c_3x3"
  name: "inception_4c_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_3x3"
  top: "inception_4c_3x3"
  name: "inception_4c_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_4b_output"
  top: "inception_4c_5x5_reduce"
  name: "inception_4c_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 24
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_5x5_reduce"
  top: "inception_4c_5x5_reduce"
  name: "inception_4c_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_4c_5x5_reduce"
  top: "inception_4c_5x5"
  name: "inception_4c_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_5x5"
  top: "inception_4c_5x5"
  name: "inception_4c_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_4b_output"
  top: "inception_4c_pool"
  name: "inception_4c_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_4c_pool"
  top: "inception_4c_pool_proj"
  name: "inception_4c_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4c_pool_proj"
  top: "inception_4c_pool_proj"
  name: "inception_4c_relu_pool_proj"
  type: RELU
}

# concatenate them all
# --------------------
layers {
  bottom: "inception_4c_1x1"
  bottom: "inception_4c_3x3"
  bottom: "inception_4c_5x5"
  bottom: "inception_4c_pool_proj"
  top: "inception_4c_output"
  name: "inception_4c_output"
  type: CONCAT
}

# ================== hierarchy 4(d) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_4c_output"
  top: "inception_4d_1x1"
  name: "inception_4d_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 112
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_1x1"
  top: "inception_4d_1x1"
  name: "inception_4d_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_4c_output"
  top: "inception_4d_3x3_reduce"
  name: "inception_4d_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 144
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_3x3_reduce"
  top: "inception_4d_3x3_reduce"
  name: "inception_4d_relu_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_4d_3x3_reduce"
  top: "inception_4d_3x3"
  name: "inception_4d_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 288
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_3x3"
  top: "inception_4d_3x3"
  name: "inception_4d_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_4c_output"
  top: "inception_4d_5x5_reduce"
  name: "inception_4d_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_5x5_reduce"
  top: "inception_4d_5x5_reduce"
  name: "inception_4d_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_4d_5x5_reduce"
  top: "inception_4d_5x5"
  name: "inception_4d_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_5x5"
  top: "inception_4d_5x5"
  name: "inception_4d_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_4c_output"
  top: "inception_4d_pool"
  name: "inception_4d_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_4d_pool"
  top: "inception_4d_pool_proj"
  name: "inception_4d_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 64
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4d_pool_proj"
  top: "inception_4d_pool_proj"
  name: "inception_4d_relu_pool_proj"
  type: RELU
}

# concatenate them all
# --------------------
layers {
  bottom: "inception_4d_1x1"
  bottom: "inception_4d_3x3"
  bottom: "inception_4d_5x5"
  bottom: "inception_4d_pool_proj"
  top: "inception_4d_output"
  name: "inception_4d_output"
  type: CONCAT
}

# ================== hierarchy 4(e) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_4d_output"
  top: "inception_4e_1x1"
  name: "inception_4e_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_1x1"
  top: "inception_4e_1x1"
  name: "inception_4e_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_4d_output"
  top: "inception_4e_3x3_reduce"
  name: "inception_4e_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_3x3_reduce"
  top: "inception_4e_3x3_reduce"
  name: "inception_4e_relu_3x3_reduce"
  type: RELU
}

layers {
  bottom: "inception_4e_3x3_reduce"
  top: "inception_4e_3x3"
  name: "inception_4e_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_3x3"
  top: "inception_4e_3x3"
  name: "inception_4e_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_4d_output"
  top: "inception_4e_5x5_reduce"
  name: "inception_4e_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_5x5_reduce"
  top: "inception_4e_5x5_reduce"
  name: "inception_4e_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_4e_5x5_reduce"
  top: "inception_4e_5x5"
  name: "inception_4e_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_5x5"
  top: "inception_4e_5x5"
  name: "inception_4e_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_4d_output"
  top: "inception_4e_pool"
  name: "inception_4e_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_4e_pool"
  top: "inception_4e_pool_proj"
  name: "inception_4e_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_4e_pool_proj"
  top: "inception_4e_pool_proj"
  name: "inception_4e_relu_pool_proj"
  type: RELU
}

# concatenate them all
# --------------------
layers {
  bottom: "inception_4e_1x1"
  bottom: "inception_4e_3x3"
  bottom: "inception_4e_5x5"
  bottom: "inception_4e_pool_proj"
  top: "inception_4e_output"
  name: "inception_4e_output"
  type: CONCAT
}


layers {
  bottom: "inception_4e_output"
  top: "pool4"
  name: "pool4"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}


# ================== hierarchy 5(a) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "pool4"
  top: "inception_5a_1x1"
  name: "inception_5a_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 256
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_1x1"
  top: "inception_5a_1x1"
  name: "inception_5a_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "pool4"
  top: "inception_5a_3x3_reduce"
  name: "inception_5a_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 160
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_3x3_reduce"
  top: "inception_5a_3x3_reduce"
  name: "inception_5a_relu_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_5a_3x3_reduce"
  top: "inception_5a_3x3"
  name: "inception_5a_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 320
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_3x3"
  top: "inception_5a_3x3"
  name: "inception_5a_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "pool4"
  top: "inception_5a_5x5_reduce"
  name: "inception_5a_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 32
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_5x5_reduce"
  top: "inception_5a_5x5_reduce"
  name: "inception_5a_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_5a_5x5_reduce"
  top: "inception_5a_5x5"
  name: "inception_5a_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_5x5"
  top: "inception_5a_5x5"
  name: "inception_5a_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "pool4"
  top: "inception_5a_pool"
  name: "inception_5a_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_5a_pool"
  top: "inception_5a_pool_proj"
  name: "inception_5a_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5a_pool_proj"
  top: "inception_5a_pool_proj"
  name: "inception_5a_relu_pool_proj"
  type: RELU
}

# concatenate them all
# --------------------
layers {
  bottom: "inception_5a_1x1"
  bottom: "inception_5a_3x3"
  bottom: "inception_5a_5x5"
  bottom: "inception_5a_pool_proj"
  top: "inception_5a_output"
  name: "inception_5a_output"
  type: CONCAT
}

# ================== hierarchy 5(b) ==================
# ====================================================

# conv 1 x 1
# ----------
layers {
  bottom: "inception_5a_output"
  top: "inception_5b_1x1"
  name: "inception_5b_1x1"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 384
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_1x1"
  top: "inception_5b_1x1"
  name: "inception_5b_relu_1x1"
  type: RELU
}

# conv 3 x 3
# ----------
layers {
  bottom: "inception_5a_output"
  top: "inception_5b_3x3_reduce"
  name: "inception_5b_3x3_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 192
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.09
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_3x3_reduce"
  top: "inception_5b_3x3_reduce"
  name: "inception_5b_relu_3x3_reduce"
  type: RELU
}
layers {
  bottom: "inception_5b_3x3_reduce"
  top: "inception_5b_3x3"
  name: "inception_5b_3x3"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_3x3"
  top: "inception_5b_3x3"
  name: "inception_5b_relu_3x3"
  type: RELU
}

# conv 5 x 5
# ----------
layers {
  bottom: "inception_5a_output"
  top: "inception_5b_5x5_reduce"
  name: "inception_5b_5x5_reduce"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 48
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.2
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_5x5_reduce"
  top: "inception_5b_5x5_reduce"
  name: "inception_5b_relu_5x5_reduce"
  type: RELU
}
layers {
  bottom: "inception_5b_5x5_reduce"
  top: "inception_5b_5x5"
  name: "inception_5b_5x5"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    weight_filler {
      type: "xavier"
      std: 0.03
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_5x5"
  top: "inception_5b_5x5"
  name: "inception_5b_relu_5x5"
  type: RELU
}

# pool 3 x 3
# ----------
layers {
  bottom: "inception_5a_output"
  top: "inception_5b_pool"
  name: "inception_5b_pool"
  type: POOLING
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layers {
  bottom: "inception_5b_pool"
  top: "inception_5b_pool_proj"
  name: "inception_5b_pool_proj"
  type: CONVOLUTION
  blobs_lr: 1
  blobs_lr: 2
  weight_decay: 1
  weight_decay: 0
  convolution_param {
    num_output: 128
    kernel_size: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layers {
  bottom: "inception_5b_pool_proj"
  top: "inception_5b_pool_proj"
  name: "inception_5b_relu_pool_proj"
  type: RELU
}

# concatenate them all
# --------------------
layers {
  bottom: "inception_5b_1x1"
  bottom: "inception_5b_3x3"
  bottom: "inception_5b_5x5"
  bottom: "inception_5b_pool_proj"
  top: "inception_5b_output"
  name: "inception_5b_output"
  type: CONCAT
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "loss3/classifier"
  top: "prob"
}